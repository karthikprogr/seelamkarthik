# -*- coding: utf-8 -*-
"""XGBM and LGBM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OCU7G-nvREzxspuB_ty6fqRIErJ-s_hX

xgboost code
"""

from numpy import loadtxt
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

dataset=loadtxt('/content/pima-indians-diabetes.data.csv',delimiter=",")
x=dataset[:,0:8]
y=dataset[:,8]

seed=7
train_size=0.33
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=train_size,random_state=seed)

model=XGBClassifier()
model.fit(x_train,y_train)

# making predicitions for test data
y_pred=model.predict(x_test)
predictions=[round(value) for value in y_pred]
predictions

accuracy=accuracy_score(y_test,predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

predictions

"""bin wise structure and largest data we can go to the the lgbm"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset=loadtxt('/content/pima-indians-diabetes.data.csv',delimiter=",")
x=dataset[:,0:8]
y=dataset[:,8]

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=0)

import lightgbm as lgb
d_train=lgb.Dataset(x_train,label=y_train)

params={}
params['learning_rate']=0.003
params['boosting_type']='gbdt'
params['objective']='binary'
params['metric']='binary_logloss'
params['sub_feature']=0.7
params['num_leaves']=50
params['min_data']=50
params['max_depth']=10

clf=lgb.train(params,d_train,100)

y_pred=clf.predict(x_test)
y_pred

predictions=[round(value) for value in y_pred]
predictions

accuracy=accuracy_score(y_test,predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

