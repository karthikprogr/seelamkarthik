# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uLNtWPnulckoCh63XK0ZuHB4cG8UWLgG
"""

#svm classification
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.preprocessing import StandardScaler

from sklearn import svm
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.svm import SVC

from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split, cross_val_score

filename=r'/content/pima-indians-diabetes.data.csv'
names=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
dataframe=pd.read_csv(filename, names=names)
array=dataframe.values
X=array[:,0:8]
Y=array[:,8]

X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3)

from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

svc=SVC()

param_grid={
    'C':[0.1,1,10],
    'kernel':['linear','rbf'],
    'gamma':[0.001,0.01,0.1,1]
}
#grid search with cross-validation
grid_search=GridSearchCV(estimator=svc,param_grid=param_grid,cv=5)
grid_search.fit(X_train,y_train)

#best parameters and best score
print("Best Parameters:",grid_search.best_params_)
print("Best cross-validation score:",grid_search.best_score_)

#grid search evaluates all possible combinations of hyperparameters, whereas random search evaluates only random subset
#grid search can be computationally expensive for large hyperparameters, spaces while random search is more efficient.
#grid seach is exhaustive ad ensures finding the best hyperparameters combination (given a limited gri while random search might miss the option)
#grid search cv and random search cv

X_train.shape, y_train.shape, X_test.shape

clf=SVC()
param_grid=[{'kernel':['rbf'],'gamma':[50,5,10,0.5],'C':[10,0.1,0.001]}]
gsv=GridSearchCV(clf,param_grid,cv=10)
gsv.fit(X_train,y_train)

gsv.best_params_,gsv.best_score_

clf=SVC(c=15,gamma=50)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_test)
acc=accuracy_score(y_test,y_pred)*100
print("Accuracy=",acc)
confusion_matrix(y_test,y_pred)

