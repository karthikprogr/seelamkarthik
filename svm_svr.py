# -*- coding: utf-8 -*-
"""SVM SVR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uLNtWPnulckoCh63XK0ZuHB4cG8UWLgG
"""

#svm classification
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.preprocessing import StandardScaler

from sklearn import svm
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.svm import SVC

from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split, cross_val_score

filename=r'/content/pima-indians-diabetes.data.csv'
names=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
dataframe=pd.read_csv(filename, names=names)
array=dataframe.values
X=array[:,0:8]
Y=array[:,8]

X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3)

from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

svc=SVC()

param_grid={
    'C':[0.1,1,10],
    'kernel':['linear','rbf'],
    'gamma':[0.001,0.01,0.1,1]
}
#grid search with cross-validation
grid_search=GridSearchCV(estimator=svc,param_grid=param_grid,cv=5)
grid_search.fit(X_train,y_train)

#best parameters and best score
print("Best Parameters:",grid_search.best_params_)
print("Best cross-validation score:",grid_search.best_score_)

#grid search evaluates all possible combinations of hyperparameters, whereas random search evaluates only random subset
#grid search can be computationally expensive for large hyperparameters, spaces while random search is more efficient.
#grid seach is exhaustive ad ensures finding the best hyperparameters combination (given a limited gri while random search might miss the option)
#grid search cv and random search cv

X_train.shape, y_train.shape, X_test.shape

"""grid search cv

"""

clf=SVC()
param_grid=[{'kernel':['rbf'],'gamma':[100,5,10,0.5],'C':[10,0.1,0.001,100]}]
gsv=GridSearchCV(clf,param_grid,cv=10)
gsv.fit(X_train,y_train)

gsv.best_params_,gsv.best_score_

clf=SVC(C=100,gamma=50)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_test)
acc=accuracy_score(y_test,y_pred)*100
print("Accuracy=",acc)
confusion_matrix(y_test,y_pred)



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error

file_path=r'/content/pima-indians-diabetes.data.csv'
column_names=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin',
              'BMI','DiabetesPedigreeFunction','Age','Outcome']
data=pd.read_csv(file_path,header=None,names=column_names)
print(data.head())

X=data.drop('Outcome',axis=1)
y=data['Outcome']

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

svr=SVR()

param_grid= {
    'C':[0.1,1,10],
    'gamma':[0.01,0.1,1],
    'kernel':['linear','rbf']
}

grid_search=GridSearchCV(estimator=svr,param_grid=param_grid,cv=5,scoring='neg_mean_squared_error')
grid_search.fit(X_train,y_train)

print("Best Parameters:",grid_search.best_params_)
print("Best cross-validation score:",grid_search.best_score_)

best_model=grid_search.best_estimator_
y_pred=best_model.predict(X_test)
mse=mean_squared_error(y_test,y_pred)
print("Mean Squared Error on test set:",mse)

